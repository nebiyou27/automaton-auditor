# src/nodes/justice.py
# ====================
# Chief Justice: deterministic synthesis (NO LLM).
# Converts judge opinions + evidence into final Markdown report.

from __future__ import annotations

from typing import Dict, List

from src.state import AgentState, JudicialOpinion


def _group_by_criterion(opinions: List[JudicialOpinion]) -> Dict[str, List[JudicialOpinion]]:
    grouped: Dict[str, List[JudicialOpinion]] = {}
    for op in opinions:
        grouped.setdefault(op.criterion_id, []).append(op)
    return grouped


def _resolve_score(opinions: List[JudicialOpinion]) -> Dict[str, object]:
    """
    Deterministic conflict resolution:
    - If large disagreement, TechLead is tiebreaker
    - Otherwise weighted average (TechLead double weight)
    """
    scores = {op.judge: op.score for op in opinions}
    prosecutor = scores.get("Prosecutor", 3)
    defense = scores.get("Defense", 3)
    techlead = scores.get("TechLead", 3)

    variance = max(scores.values()) - min(scores.values()) if scores else 0
    if variance > 2:
        return {
            "final_score": techlead,
            "reason": f"High variance detected (P={prosecutor}, D={defense}, T={techlead}). TechLead used as tiebreaker.",
        }

    final_score = round((prosecutor + defense + 2 * techlead) / 4)
    return {
        "final_score": final_score,
        "reason": f"Weighted scoring: P={prosecutor}, D={defense}, T={techlead} (double).",
    }


def chief_justice(state: AgentState) -> Dict[str, str]:
    opinions = state.get("opinions", []) or []
    evidences = state.get("evidences", {}) or {}

    grouped = _group_by_criterion(opinions)
    if not grouped:
        grouped = {"detective_phase": []}

    sections: List[str] = []
    total = 0
    count = 0

    for criterion_id, ops in grouped.items():
        if ops:
            resolution = _resolve_score(ops)
            final_score = int(resolution["final_score"])
            reason = str(resolution["reason"])
        else:
            final_score = 0
            reason = "No judge opinions available."

        total += final_score
        count += 1

        dissent_lines = []
        for op in ops:
            dissent_lines.append(f"- **{op.judge}** (Score {op.score}/5): {op.argument}")
            if op.cited_evidence:
                dissent_lines.append(f"  - Cited: {', '.join(op.cited_evidence)}")

        sections.append(
            f"""## Criterion: {criterion_id}
**Final Score:** {final_score}/5

### Dissent (Judge Opinions)
{chr(10).join(dissent_lines) if dissent_lines else "- No opinions."}

### Deterministic Resolution
{reason}
"""
        )

    avg = round(total / count) if count else 0

    evidence_summary = []
    for bucket, items in evidences.items():
        found = sum(1 for e in items if e.found)
        evidence_summary.append(f"- **{bucket.upper()}**: {found}/{len(items)} found")

    report = f"""# AUTOMATON AUDITOR â€” FINAL VERDICT

## Executive Summary
- **Repository:** {state.get("repo_url", "N/A")}
- **PDF:** {state.get("pdf_path", "N/A") or "None"}
- **Overall Score:** {avg}/5

## Evidence Summary
{chr(10).join(evidence_summary) if evidence_summary else "- No evidence collected."}

---

{chr(10).join(sections)}

---

## Remediation Checklist (General)
- Ensure all required artifacts exist and are verifiable (README claims must match repo reality)
- Keep detective outputs purely factual; keep all scoring inside judges
- Maintain parallel fan-out/fan-in patterns with safe reducers
- Keep tool execution sandboxed and error-handled

*Generated by Chief Justice (deterministic synthesis, no LLM).*
"""

    return {"final_report": report}